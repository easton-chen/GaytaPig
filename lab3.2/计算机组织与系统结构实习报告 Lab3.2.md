# 计算机组织与体系结构实习报告 Lab3.1
学号：1500012863

姓名：杨程旭

大班教师：程旭

----

## cache管理策略优化（70分）
#### 根据Lab 3.2实习指导的要求，对默认配置下Cache进行优化。并使用附件中所给测试trace，对优化前后的cache进行比较。
1. 请填写以下参数。（10分）
- 默认配置下，32nm工艺节点下，L1 Cache的 Hit Latency 为（ 1.47944 ）ns，约等于 （   3   ）cycle
- 默认配置下，32nm工艺节点下，L2 Cache的 Hit Latency 为（ 1.92060 ）ns，约等于 （   4   ）cycle


2. 默认配置下，运行2.trace，结果如下：（10分）
- **1.trace**

- 运行次数：run num = ( 10 )

- L1 Cache： Miss Rate = （ 0.955490 ）

- L2 Cache： Miss Rate = （  0.443988  ）

- AMAT =(  49.24  )

- **2.trace**

- 运行次数：run num = ( 10 )

- L1 Cache： Miss Rate = （ 0.000095 ）

- L2 Cache： Miss Rate = （  1.00  ）

- AMAT =(  3.01  )

  *注意：该部分数值应与实际运行结果一致*


3. 请填写最终确定的优化方案，并陈述理由。对于涉及到的算法，需要详细描述算法设计和实现思路，并给出优缺点分析。（40分）

    **整体的优化方案如下表所示：**

    |  cache   | Prefetch | Bypass | 替换策略 |
    | :------: | :------: | :----: | :--: |
    | L1 Cache |    Y     |   Y    | LRU  |
    | L2 Cache |    Y     |   Y    | LIRS |

    **分析如下：**

    **Prefetch：**

    ​	预取对于Cache性能的提升是非常重要的，具体的做法是当cache发生miss的时候，假设此时发生miss的地址为Addr，就会从下层cache中预取4个block，从Addr+1×block size到Addr + 4×block size，如果其中某个已经在cache中了，就不进行预取。这样做的好处在于当访问的空间局部性较强时，一次miss过后，之后的几次访问都有很大的可能性访问到预取的cache，从而大大减少miss rate。

    ​

    **Bypass：**

    ​	Bypass的思想是：假设一个cache发生了miss，我们根据之前的历史信息判断出，这个块接下来被访问的概率较小，就不让这个块进入cache，从而使cache中尽可能保留经常被访问的块，减少没有意义的频繁的换入换出。个人认为，此次的bypass其实对于本次访存的时间并不会产生影响，因为他还是要从下层找，依旧是一次miss，只是是否进入cache的区别，他的影响在于后续的访问，假如之后的访问恰好访问了本应该被换出的块，由于bypass这一个块并没有被换出，这时访存的时间就减少了。

    ​	具体实现上：我们为cache的每一个set维护一个map，map记录了每一个进入过这个set的tag和这个tag的频次（set和tag就可以决定是哪一个块）。当发生了一次cache miss的时候，我们取这个tag的频次，假如低于这个set的阈值频次的话，我们就认为这个tag被访问的概率较低，应该把这一个块bypass掉。set的阈值频次其实是一个函数，与set的状态和set里面的块相关，当set还有空的block时，这个阈值就会很小，使得任意一个tag都可以进入而不被bypass掉，当set中没有空block时，我们取最大频次和2倍最小频次的加和除以3（相当于最大频次和最小频次的三等分点）作为阈值，因此说阈值是和set的状况相关的。至于为何选三等分点，这是多次实验后的调参结果，针对1.trace有较好的表现。

    ​	优化的力度上：根据多次的比较，bypass的针对1.trace还有2.trace的优化是非常有限的，1.trace的miss rate下降了1%,2.trace没有变化，也许这就是如今很少有cache选择这种策略的原因吧。

    ​

    **LRU：**

    ​	根据时间局部性原理，在前面几次访存频繁使用的块很可能在后面几次访存中频繁使用，反过来说，已经很久没有使用的块很可能在未来较长一段时间内不会被用到。LRU的思想就是在需要替换时，把最近最远被使用过的块替换掉。

    ​	LRU的实现方式也很简单：为每一个存在cache中的块维护一个时间戳，记录其上一次被访问的时间，如果cache命中则更新对应块的时间戳，否则选择时间戳最小的块进行替换。

    ​	LRU的优点是简洁而且在大部分时间都有不错的表现。但是LRU也有自己的问题：1）对冷数据突发性访问抵抗能力差，可能会因此淘汰掉热的文件。好的算法里：热文件不应该被冷文件淘汰掉。2）对于大量数据的循环访问抵抗能力查，极端情况下可能会出现命中率0%。好的算法里：这种情况miss rate应该约等于buffer space shortage ratio。

    ​

    **LIRS：**

    ​	首先我们来构造一个使用LRU会性能很差的场景：考虑这样一种情况，循环内的数据集大小为101，cache总的大小为100，在循环中对数据进行顺序访问，可以看到，几次循环下来几乎没有cache命中的情况，很多块都是在将要被访问到的时候被替换掉了。

    ​	LRU的局限性在于，没有对块的使用频次进行考虑。这就造成了常使用的块（热块）和不常使用的块（冷块）是不加区别的。LIRS替换算法解决了这一问题，首先LIRS算法使用两个参数来衡量一个cache 块，分别是IRR(Inter-Reference Recency)和R（Recency），IRR为一个页面最近两次的访问间隔，当第一次被访问时IRR的值为无穷大（inf）。R为页面最近一次访问到当前时间内有多少页面曾经被访问过（LRU数值）。LIRS算法将数据块分为LIR和HIR两级的方式：1）LIR：热数据块，已经被访问两次的数据块。2）HIR：冷数据块，还仅仅只被访问一次的数据块。在淘汰时，选择IRR最大的块，代表其不经常被访问，如果某些块的IRR值相同，则淘汰这些块中R最大的块。在这里IRR是对频次的考虑，R是对上次访问时间的考虑。

    ​	LIRS的具体实现上：考虑到硬件上，为每一个块维护和更新IRR和R这两个值的开销是巨大的（通常需要遍历访问的序列），因此在真正的实现上，并不真正计算IRR和R。我们设置两个队列S和Q，S队列负责热数据（LIR块）淘汰，Q队列中负责冷数据（HIR块）淘汰。队列S中的块可能是LIR块，也可能是HIR块，LIR块一定驻留在cache中，HIR块不一定驻留在cache中，驻留的记为resident HIR，未驻留记为non-resident HIR。队列Q中的块都是resident HIR块。此外，队列S的队尾元素一定要是LIR块，如果是HIR块直接弹出队尾，这一操作称为“剪枝”。算法的具体思路是：

    当访问一个block时，可能会出现如下情况：

    1.访问S队列中的LIR块：将其移至队首，如果这个LIR块原本在队尾，则移动后进行剪枝。

    2.访问某个未曾出现过的块：有两种情况：

    1）如果LIR块的数量没有到达上限（在一个set中，LIR块和resident HIR块的数量都有上限，且加和为set的相联度），将这个块置为LIR块，放入S队列队首。

    2）如果LIR块数量到达上限，若Q队列未满（即HIR块数量未达到上限），则将此块置为HIR块，放入S和Q队列队首，否则，从Q队列中弹出队尾块作为被替换的块，并将此块置为HIR块，放入S和Q队列队首。

    3.访问S队列中出现的HIR块：有两种情况：

    1）这个块是一个resident-HIR块，把他在Q队列和S队列中的对应块删除，将其置为LIR块放入S队列队首，且S队尾弹出一个LIR块，把他降级为resident HIR块放入Q队列。

    2）这是一个non-resident HIR块，把他在S队列中的对应块删除，从Q队列队尾弹出一个resident HIR块作为被替换的块，替换块（原先S队列删除掉的，也就是此次访问的块）置为LIR块放入S队列队首，且S队尾弹出一个LIR块，把他降级为resident HIR块放入Q队列。

    针对此次lab中cache的配置，将LIR块的上限设置为6，HIR块的上线设置为2。

    > 参考资料：https://www.qcloud.com/community/article/606626

    ​

4. 优化配置下，运行2.trace，结果如下：（10分）
- **1.trace**

- 运行次数：run num = ( 10 )

- L1 Cache： Miss Rate = （ 0.477350 ）

- L2 Cache： Miss Rate = （  0.556288  ）

- AMAT =(  34.33  )

- **2.trace**

- 运行次数：run num = ( 10 )

- L1 Cache： Miss Rate = （  0.000040  ）

- L2 Cache： Miss Rate = （  1.000000  ）

- AMAT =(      3.00        )

  *注意：该部分数值应与实际运行结果一致*

## cache性能优化测试排名（30分）